# ğŸ§  Mixup Reproduction & Extension

This project reproduces and extends the results of **Mixup: Beyond Empirical Risk Minimization** (Zhang et al., 2018).  
It replicates the original experiments on **CIFAR-10**, **CIFAR-100**, and **Speech Commands**, and further tests Mixup on **Fashion-MNIST** to evaluate its generalization performance on unseen data.

---

## ğŸš€ Features

- Full reproduction of Mixup experiments for image and audio classification  
- Implementations of **ResNet-18 (PreAct)**, **Wide-ResNet-28-10**, and **VGG11**  
- Additional experiments on **Fashion-MNIST** (grayscale)  
- Spectrogram-level Mixup for audio data  
- Unified training pipeline with Mixup and ERM baselines  
- Reproducible results with GPU/CPU support  

---

## ğŸ§± Project Structure

```
mixup/
â”œâ”€â”€ train2.py                 # Unified trainer for classification + Mixup
â”œâ”€â”€ models/
â”‚   â””â”€â”€ resnet.py             # ResNet18_* architectures with PreAct blocks
â”œâ”€â”€ command_dataset.py        # Speech Commands loader (16 kHz â†’ spectrograms)
â”œâ”€â”€ utils.py                  # Progress bar and helper utilities
â”œâ”€â”€ results/                  # CSV logs (auto-generated)
â”œâ”€â”€ checkpoint/               # Model checkpoints (auto-generated)
â”œâ”€â”€ THIRD_PARTY_NOTICES.md
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Tech Stack

| Component      | Library/Framework                    |
|----------------|--------------------------------------|
| Deep Learning  | PyTorch 2.8.0 + CUDA 12.6            |
| Datasets       | Torchvision (CIFAR, Fashion-MNIST)   |
| Audio Handling | Torchaudio + Spectrogram Transform   |
| Models         | ResNet-18, WideResNet-28-10, VGG11   |
| Augmentation   | Mixup (linear interpolation)         |
| Logging        | CSV output + progress bar            |

---

## âš™ï¸ Setup

### ğŸ§© Environment Setup

```bash
conda create -n mixup python=3.10 -y
conda activate mixup
pip install torch==2.8.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
pip install numpy tqdm matplotlib pyyaml
```

---

## ğŸ“¦ Datasets

- **CIFAR-10 / CIFAR-100**: Auto-downloaded via `torchvision.datasets`
- **Fashion-MNIST**: Drop-in grayscale benchmark (fixed 1-channel)
- **Speech Commands**: Converted to spectrograms (160Ã—101) at 16 kHz  
  *(see `command_dataset.py` for path configuration)*

Default data root: `~/data`  
Override with `--data-root /path/to/data`

---

## â–¶ï¸ Quickstart

### ğŸ§© CIFAR-10 / CIFAR-100
Baseline (ERM, no Mixup):
```bash
python -u train.py --model ResNet18_CIFAR10 --dataset CIFAR10   --adjustlr 100-150 --lr 0.1 --alpha 0 --seed 42 --name ResNet_C10 
```

Mixup (Î± = 1.0):
```bash
python -u train.py --model ResNet18_CIFAR10 --dataset CIFAR10   --adjustlr 100-150 --lr 0.1 --alpha 1.0 --seed 42 --name ResNet_C10_Mixup 
```

CIFAR-100:
```bash
python -u train.py --model ResNet18_CIFAR100 --dataset CIFAR100   --adjustlr 100-150 --lr 0.1 --alpha 1.0 --seed 42 --name ResNet_C100_Mixup
```

### ğŸ‘• Fashion-MNIST

```bash
python -u train.py --model ResNet18_FMNIST --dataset FASHIONMNIST   --adjustlr 100-150 --lr 0.1 --alpha 1.0 --seed 42 --name ResNet_FMNIST 
```

### ğŸ§ Speech Commands
VGG11 (spectrogram-level Mixup):
```bash
python -u train.py --model VGG11 --dataset COMMAND   --lr 0.001 --alpha 1.0 --epoch 30 --batch-size 128 --seed 42   --name VGG11_Commands
```

---

## ğŸ“Š Results Summary

| Dataset | Model | ERM (Test Err %) | Mixup (Test Err %) | Observation |
|----------|--------|------------------|--------------------|--------------|
| CIFAR-10 | ResNet-18 | 5.2 | 4.3 | Matches original trend |
| CIFAR-100 | ResNet-18 | 24.4 | 22.5 | Slight improvement |
| FMNIST | ResNet-18 | 7.3 | 6.4 | Improved generalization |
| Commands | VGG11 | 4.1 | 3.8 | Stable across seeds |

Results align closely with the Mixup paper; small deviations arise from hardware and random seed differences.

---

## ğŸ“ Logs & Checkpoints

| Output | Path |
|---------|------|
| Training logs | `results/log_<Model>_<RunName>_<Seed>.csv` |
| Checkpoints | `checkpoint/ckpt_<RunName>_{best|last}_<Seed>.pt` |

---

## ğŸ“˜ Acknowledgments & Licenses

- **Mixup:** Zhang *et al.* (ICLR 2018)  
- **CIFAR, Fashion-MNIST, Speech Commands:** via `torchvision`  
- PreAct ResNet structure adapted from open-source examples (MIT/BSD)  
---

## ğŸ§¾ Citation

If you use this project, please cite:

```bibtex
@inproceedings{zhang2018mixup,
  title={mixup: Beyond Empirical Risk Minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N. and Lopez-Paz, David},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}
```

---

## ğŸ§© Troubleshooting

| Issue | Solution |
|--------|-----------|
| **Windows DataLoader freeze** | use `--num-workers 0` |
| **CUDA not detected** | verify PyTorch CUDA build matches driver |
| **FMNIST channel mismatch** | repo fixed to 1-channel; use `ResNet18_FMNIST` |
| **No output** | run with `-u` flag and check `results/` for CSV logs |
---

## ğŸ“„ License

MIT License Â© 2025 Dinh Tuan Tran
